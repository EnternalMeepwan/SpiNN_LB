{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2017-2019 The University of Manchester\n",
    "#\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "from collections import OrderedDict\n",
    "from enum import Enum\n",
    "import struct\n",
    "\n",
    "from spinn_front_end_common.abstract_models import AbstractProvidesNKeysForPartition\n",
    "from spinn_utilities.overrides import overrides\n",
    "from pacman.executor.injection_decorator import inject_items\n",
    "from pacman.model.graphs.machine import MachineVertex\n",
    "from pacman.model.resources import ResourceContainer, VariableSDRAM\n",
    "from pacman.utilities.utility_calls import is_single\n",
    "from spinn_front_end_common.utilities.constants import (\n",
    "    SYSTEM_BYTES_REQUIREMENT, BYTES_PER_WORD)\n",
    "from spinn_front_end_common.utilities.exceptions import ConfigurationException\n",
    "from spinn_front_end_common.utilities.helpful_functions import (\n",
    "    locate_memory_region_for_placement)\n",
    "from spinn_front_end_common.abstract_models.impl import (\n",
    "    MachineDataSpecableVertex)\n",
    "from spinn_front_end_common.interface.buffer_management.buffer_models import (\n",
    "    AbstractReceiveBuffersToHost)\n",
    "from spinn_front_end_common.interface.buffer_management import (\n",
    "    recording_utilities)\n",
    "from spinnaker_graph_front_end.utilities import SimulatorVertex\n",
    "from spinnaker_graph_front_end.utilities.data_utils import (\n",
    "    generate_system_data_region)\n",
    "\n",
    "from data_specification.enums.data_type import DataType\n",
    "\n",
    "from spinn_front_end_common.utilities import exceptions\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class LatticeBasicCell(\n",
    "    SimulatorVertex, MachineDataSpecableVertex,\n",
    "    AbstractReceiveBuffersToHost,\n",
    "    AbstractProvidesNKeysForPartition\n",
    "):\n",
    "    \"\"\" A Boltzmann Lattice which represents a cell within the 2d fabric\n",
    "    \"\"\"\n",
    "    \n",
    "    PARTITION_ID = \"STATE\"\n",
    "\n",
    "    TRANSMISSION_DATA_SIZE = 2 * BYTES_PER_WORD  # has key and key\n",
    "    STATE_DATA_SIZE = BYTES_PER_WORD  # 1 or 2 based off dead or alive\n",
    "    # alive states, dead states\n",
    "    NEIGHBOUR_INITIAL_STATES_SIZE = 2 * BYTES_PER_WORD\n",
    "    RECORDING_ELEMENT_SIZE = STATE_DATA_SIZE  # A recording of the volocity\n",
    "\n",
    "    POSITION_DATA_SIZE = 2 * BYTES_PER_WORD # x position and y position\n",
    "\n",
    "    NEIGHBOUR_KEYS_SIZE = 9 * BYTES_PER_WORD  # for 8 directions and a mask\n",
    "\n",
    "    VELOCITY_SIZE = 2 * BYTES_PER_WORD  # u_x and u_y\n",
    "\n",
    "    VERTEX_INDEX_SIZE = BYTES_PER_WORD # the index of the lattice in the network\n",
    "\n",
    "    # The order of which directions are writeen to sdram\n",
    "    ORDER_OF_DIRECTIONS = [\"N\", \"W\", \"S\", \"E\", \"NW\", \"SW\", \"SE\", \"NE\"]\n",
    "    # Regions for populations\n",
    "    DATA_REGIONS = Enum(\n",
    "        value=\"DATA_REGIONS\",\n",
    "        names=[('SYSTEM', 0),\n",
    "               ('TRANSMISSIONS', 1),\n",
    "               ('POSITION', 2),\n",
    "               ('NEIGHBOUR_KEYS', 3),\n",
    "               ('VELOCITY', 4),\n",
    "               ('VERTEX_INDEX', 5),\n",
    "               ('RESULTS', 6)])\n",
    "\n",
    "    def __init__(self, label, x_position, y_position, u_x, u_y):\n",
    "        super(LatticeBasicCell, self).__init__(label, \"lattice_cell.aplx\")\n",
    "        AbstractProvidesNKeysForPartition.__init__(self)\n",
    "        # app specific data items\n",
    "        self._x_position = x_position\n",
    "        self._y_position = y_position\n",
    "        self.u_x = u_x\n",
    "        self.u_y = u_y\n",
    "\n",
    "        self._loccation_vertices = OrderedDict()\n",
    "        for direction in self.ORDER_OF_DIRECTIONS:\n",
    "            self._loccation_vertices[direction] = None\n",
    "\n",
    "    def set_direction_vertex(self, direction, vertex):\n",
    "        \"\"\"\n",
    "        Add a vertex to the corresponding direction\n",
    "        \"\"\"\n",
    "        self._loccation_vertices[direction] = vertex\n",
    "\n",
    "    def _write_key_data(self, spec, routing_info, graph):\n",
    "        \"\"\"\n",
    "        Write the keys of its 8 neighbours\n",
    "        \"\"\"\n",
    "        spec.switch_write_focus(region=self.DATA_REGIONS.NEIGHBOUR_KEYS.value)\n",
    "        incoming_edges = graph.get_edges_ending_at_vertex_with_partition_name(self, self.PARTITION_ID)\n",
    "\n",
    "        # verify the number of edges\n",
    "        if len(incoming_edges) != 8:\n",
    "            print(incoming_edges)\n",
    "            raise exceptions.ConfigurationException(\"Should only have 8 edges\")\n",
    "\n",
    "        # get incoming edges\n",
    "        for direction in self._loccation_vertices:\n",
    "            key = routing_info.get_routing_info_from_pre_vertex(\n",
    "                self._loccation_vertices[direction],\n",
    "                self.PARTITION_ID).keys_and_masks[0].key\n",
    "            if key is not None:\n",
    "                spec.write_value(data=key)\n",
    "            else:\n",
    "                logger.warning(\"This lattice miss a edge from direction {}\".format(direction))\n",
    "                spec.write_value(data_type=DataType.INT32, data=-1)\n",
    "\n",
    "        mask = routing_info.get_routing_info_from_pre_vertex(self._loccation_vertices[\"S\"],\n",
    "                                                             self.PARTITION_ID).keys_and_masks[0].mask\n",
    "        spec.write_value(data=mask, data_type=DataType.UINT32)\n",
    "\n",
    "    @inject_items({\"data_n_time_steps\": \"DataNTimeSteps\"})\n",
    "    @overrides(\n",
    "        MachineDataSpecableVertex.generate_machine_data_specification,\n",
    "        additional_arguments={\"data_n_time_steps\"})\n",
    "    def generate_machine_data_specification(\n",
    "            self, spec, placement, machine_graph, routing_info, iptags,\n",
    "            reverse_iptags, machine_time_step, time_scale_factor,\n",
    "            data_n_time_steps):\n",
    "        # Generate the system data region for simulation .c requirements\n",
    "        generate_system_data_region(spec, self.DATA_REGIONS.SYSTEM.value,\n",
    "                                    self, machine_time_step, time_scale_factor)\n",
    "\n",
    "        # reserve memory regions for every data region\n",
    "        spec.reserve_memory_region(\n",
    "            region=self.DATA_REGIONS.TRANSMISSIONS.value,\n",
    "            size=self.TRANSMISSION_DATA_SIZE, label=\"inputs\")\n",
    "\n",
    "        spec.reserve_memory_region(\n",
    "            region=self.DATA_REGIONS.POSITION.value,\n",
    "            size=self.POSITION_DATA_SIZE, label=\"position\"\n",
    "        )\n",
    "\n",
    "        spec.reserve_memory_region(\n",
    "            region=self.DATA_REGIONS.NEIGHBOUR_KEYS.value,\n",
    "            size=self.NEIGHBOUR_KEYS_SIZE\n",
    "        )\n",
    "\n",
    "        spec.reserve_memory_region(\n",
    "            region=self.DATA_REGIONS.VELOCITY.value,\n",
    "            size=self.VELOCITY_SIZE\n",
    "        )\n",
    "\n",
    "        spec.reserve_memory_region(\n",
    "            region=self.DATA_REGIONS.VERTEX_INDEX.value,\n",
    "            size=self.VERTEX_INDEX_SIZE\n",
    "        )\n",
    "\n",
    "        spec.reserve_memory_region(\n",
    "            region=self.DATA_REGIONS.RESULTS.value,\n",
    "            size=recording_utilities.get_recording_header_size(1))\n",
    "\n",
    "        # get recorded buffered regions sorted\n",
    "        spec.switch_write_focus(self.DATA_REGIONS.RESULTS.value)\n",
    "        spec.write_array(recording_utilities.get_recording_header_array(\n",
    "            [self.RECORDING_ELEMENT_SIZE * data_n_time_steps]))\n",
    "\n",
    "        # check got right number of keys and edges going into me\n",
    "        partitions = \\\n",
    "            machine_graph.get_outgoing_edge_partitions_starting_at_vertex(self)\n",
    "        if not is_single(partitions):\n",
    "            raise ConfigurationException(\n",
    "                \"Can only handle one type of partition.\")\n",
    "\n",
    "        # check for duplicates\n",
    "        edges = list(machine_graph.get_edges_ending_at_vertex(self))\n",
    "        if len(edges) != 8:\n",
    "            raise ConfigurationException(\n",
    "                \"I've not got the right number of connections. I have {} \"\n",
    "                \"instead of 8\".format(\n",
    "                    len(machine_graph.get_edges_ending_at_vertex(self))))\n",
    "\n",
    "        for edge in edges:\n",
    "            if edge.pre_vertex == self:\n",
    "                raise ConfigurationException(\n",
    "                    \"I'm connected to myself, this is deemed an error\"\n",
    "                    \" please fix.\")\n",
    "\n",
    "        # write key needed to transmit with\n",
    "        key = routing_info.get_first_key_from_pre_vertex(\n",
    "            self, self.PARTITION_ID)\n",
    "\n",
    "        spec.switch_write_focus(\n",
    "            region=self.DATA_REGIONS.TRANSMISSIONS.value)\n",
    "        spec.write_value(0 if key is None else 1)\n",
    "        spec.write_value(0 if key is None else key)\n",
    "\n",
    "        # write POSITION data\n",
    "        spec.switch_write_focus(\n",
    "            region=self.DATA_REGIONS.POSITION.value\n",
    "        )\n",
    "        spec.write_value(int(self._x_position))\n",
    "        spec.write_value(int(self._y_position))\n",
    "\n",
    "        #write VERTEX_INDEX data. Mainly for add a random delay\n",
    "        spec.switch_write_focus(region=self.DATA_REGIONS.VERTEX_INDEX.value)\n",
    "        spec.write_value(machine_graph.vertices.index(self))\n",
    "\n",
    "        # write the neighbour keys and masks\n",
    "        self._write_key_data(spec, routing_info, machine_graph)\n",
    "\n",
    "        #write velocity data in two dimension, x and y\n",
    "        spec.switch_write_focus(region=self.DATA_REGIONS.VELOCITY.value)\n",
    "        spec.write_value(self.u_x, data_type=DataType.FLOAT_32)\n",
    "        spec.write_value(self.u_y, data_type=DataType.FLOAT_32)\n",
    "\n",
    "        # End-of-Spec:\n",
    "        spec.end_specification()\n",
    "\n",
    "    def get_data(self, buffer_manager, placement):\n",
    "        # for buffering output info is taken form the buffer manager\n",
    "        # get raw data, convert to list of booleans\n",
    "        raw_data, data_missing = buffer_manager.get_data_by_placement(\n",
    "            placement, 0)\n",
    "\n",
    "        # do check for missing data\n",
    "        if data_missing:\n",
    "            print(\"missing_data from ({}, {}, {}); \".format(\n",
    "                placement.x, placement.y, placement.p))\n",
    "\n",
    "        # return the data, converted to list of booleans\n",
    "        return [\n",
    "            element\n",
    "            for element in struct.unpack(\n",
    "                \"<{}f\".format(len(raw_data) // BYTES_PER_WORD), raw_data)]\n",
    "\n",
    "    @property\n",
    "    @overrides(MachineVertex.resources_required)\n",
    "    def resources_required(self):\n",
    "        \"\"\"\n",
    "        Reserve resources for data regions\n",
    "        \"\"\"\n",
    "        fixed_sdram = (SYSTEM_BYTES_REQUIREMENT + self.TRANSMISSION_DATA_SIZE +\n",
    "                       self.POSITION_DATA_SIZE +\n",
    "                       self.NEIGHBOUR_KEYS_SIZE +\n",
    "                       self.VELOCITY_SIZE +\n",
    "                       self.VERTEX_INDEX_SIZE +\n",
    "                       recording_utilities.get_recording_header_size(1) +\n",
    "                       recording_utilities.get_recording_data_constant_size(1))\n",
    "        per_timestep_sdram = self.RECORDING_ELEMENT_SIZE\n",
    "        return ResourceContainer(\n",
    "            sdram=VariableSDRAM(fixed_sdram, per_timestep_sdram))\n",
    "\n",
    "    @property\n",
    "    def x_position(self):\n",
    "        return self._x_position\n",
    "\n",
    "    @overrides(AbstractProvidesNKeysForPartition.get_n_keys_for_partition)\n",
    "    def get_n_keys_for_partition(self, partition, graph_mapper):\n",
    "        \"\"\"\n",
    "        Ask for 8 keys for every lattice for the transmission of 8 fi\n",
    "        \"\"\"\n",
    "        return 8  # for its 8 neighbours to send\n",
    "\n",
    "    @property\n",
    "    def y_position(self):\n",
    "        return self._y_position\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.label\n",
    "\n",
    "    @overrides(AbstractReceiveBuffersToHost.get_recorded_region_ids)\n",
    "    def get_recorded_region_ids(self):\n",
    "        return [0]\n",
    "\n",
    "    @overrides(AbstractReceiveBuffersToHost.get_recording_region_base_address)\n",
    "    def get_recording_region_base_address(self, txrx, placement):\n",
    "        return locate_memory_region_for_placement(\n",
    "            placement, self.DATA_REGIONS.RESULTS.value, txrx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pacman.model.graphs.machine import MachineEdge\n",
    "\n",
    "\n",
    "class LatticeEdge(MachineEdge):\n",
    "    \"\"\"\n",
    "    Used for conjunction with a lattice\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pre_vertex, post_vertex, compass, label=None):\n",
    "        MachineEdge.__init__(\n",
    "            self, pre_vertex, post_vertex, label=label)\n",
    "        self._compass = compass\n",
    "\n",
    "    @property\n",
    "    def compass(self):\n",
    "        return self._compass\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"LatticeEdge: {}:{}\".format(self._compass, self._label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-19 19:05:11 INFO: Read cfg files: /home/spinnaker/sPyNNaker/lib/python3.6/site-packages/spinn_front_end_common/interface/spinnaker.cfg, /home/spinnaker/sPyNNaker/lib/python3.6/site-packages/spinnaker_graph_front_end/spiNNakerGraphFrontEnd.cfg, /home/spinnaker/.spiNNakerGraphFrontEnd.cfg\n",
      "2020-07-19 19:05:11 INFO: Will search these locations for binaries: /home/spinnaker/sPyNNaker/lib/python3.6/site-packages/spinn_front_end_common/common_model_binaries : /home/spinnaker\n",
      "2020-07-19 19:05:11 WARNING: /home/spinnaker/reports has 47 old reports that have not been closed\n",
      "2020-07-19 19:05:11 WARNING: /home/spinnaker/application_generated_data_files has 143 old reports that have not been closed\n",
      "2020-07-19 19:05:11 INFO: Setting time scale factor to 10.\n",
      "2020-07-19 19:05:11 INFO: Setting machine time step to 10000 micro-seconds.\n",
      "Created spalloc job 5336188\n",
      "2020-07-19 19:05:11 INFO: Created spalloc job 5336188\n",
      "Waiting for board power commands to complete.\n",
      "2020-07-19 19:05:11 INFO: Waiting for board power commands to complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/spinnaker/sPyNNaker/lib/python3.6/site-packages/spinn_front_end_common/interface/spinnaker.cfg', '/home/spinnaker/sPyNNaker/lib/python3.6/site-packages/spinnaker_graph_front_end/spiNNakerGraphFrontEnd.cfg', '/home/spinnaker/.spiNNakerGraphFrontEnd.cfg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-19 19:05:20 INFO: Time 0:00:09.039356 taken by SpallocAllocator\n",
      "2020-07-19 19:05:20 INFO: Creating transceiver for 10.11.203.17\n",
      "2020-07-19 19:05:20 INFO: Working out if machine is booted\n",
      "2020-07-19 19:05:24 INFO: Attempting to boot machine\n",
      "2020-07-19 19:05:39 INFO: Found board with version [Version: SC&MP 3.2.5 at SpiNNaker:0:0:0 (built Thu Aug  1 08:15:06 2019)]\n",
      "2020-07-19 19:05:39 INFO: Machine communication successful\n",
      "2020-07-19 19:05:39 WARNING: Link 44311 points to Chip (45, 32) but that is not included \n",
      "2020-07-19 19:05:39 WARNING: Link 44320 points to Chip (45, 32) but that is not included \n",
      "2020-07-19 19:05:39 WARNING: Link 45312 points to Chip (45, 32) but that is not included \n",
      "2020-07-19 19:05:39 WARNING: Link 45335 points to Chip (45, 32) but that is not included \n",
      "2020-07-19 19:05:39 WARNING: Link 46323 points to Chip (45, 32) but that is not included \n",
      "2020-07-19 19:05:39 WARNING: Link 46334 points to Chip (45, 32) but that is not included \n",
      "2020-07-19 19:05:39 INFO: Detected a machine on IP address 10.11.203.17 which has 30550 cores and 4891.0 links\n",
      "2020-07-19 19:05:39 INFO: Time 0:00:19.085589 taken by MachineGenerator\n",
      "Pre allocating resources for Extra Monitor support vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:05:39 INFO: Time 0:00:00.372288 taken by PreAllocateResourcesForExtraMonitorSupport\n",
      "2020-07-19 19:05:41 INFO: Starting execution process\n",
      "2020-07-19 19:05:43 INFO: Time 0:00:00.284862 taken by NetworkSpecificationReport\n",
      "Allocating virtual identifiers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:05:46 INFO: Time 0:00:02.780607 taken by MallocBasedChipIDAllocator\n",
      "Inserting extra monitors into graphs\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:05:46 INFO: Time 0:00:00.370286 taken by InsertExtraMonitorVerticesToGraphs\n",
      "Writing the board chip report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:05:46 INFO: Time 0:00:00.022297 taken by BoardChipReport\n",
      "Placing graph vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:05:50 INFO: Time 0:00:04.089536 taken by RadialPlacer\n",
      "Inserting edges between vertices which require FR speed up functionality.\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:05:53 INFO: Time 0:00:02.715251 taken by InsertEdgesToExtraMonitorFunctionality\n",
      "Generating routing tables for data in system processes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:05:53 INFO: Time 0:00:00.076424 taken by DataInMulticastRoutingGenerator\n",
      "Generating fixed router routes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:05:53 INFO: Time 0:00:00.042401 taken by FixedRouteRouter\n",
      "Routing\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "2020-07-19 19:06:03 INFO: Time 0:00:09.912640 taken by NerRoute\n",
      "Discovering tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Allocating tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:06 INFO: Time 0:00:03.044756 taken by BasicTagAllocator\n",
      "Reporting Tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:06 INFO: Time 0:00:00.024353 taken by TagReport\n",
      "Getting number of keys required by each edge using machine graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:09 INFO: Time 0:00:02.683013 taken by EdgeToNKeysMapper\n",
      "Getting constraints for machine graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:11 INFO: Time 0:00:02.806260 taken by ProcessPartitionConstraints\n",
      "Allocating routing keys\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:24 INFO: Time 0:00:12.742351 taken by MallocBasedRoutingInfoAllocator\n",
      "Generating Routing info report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:27 INFO: Time 0:00:03.113488 taken by routingInfoReports\n",
      "Generating routing tables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:31 INFO: Time 0:00:04.020365 taken by BasicRoutingTableGenerator\n",
      "Finding executable start types\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:35 INFO: Time 0:00:03.427937 taken by LocateExecutableStartType\n",
      "Initialising buffers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:37 INFO: Time 0:00:02.753339 taken by BufferManagerCreator\n",
      "Generating data specifications\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:53 INFO: Time 0:00:15.294590 taken by GraphDataSpecificationWriter\n",
      "Preparing Routing Tables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:06:56 INFO: Time 0:00:03.168916 taken by RoutingSetup\n",
      "Finding binaries\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:07:00 INFO: Time 0:00:03.598156 taken by GraphBinaryGatherer\n",
      "Running routing table compression on chip\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:07:19 INFO: Time 0:00:19.802078 taken by MundyOnChipRouterCompression\n",
      "Generating Router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:07:22 INFO: Time 0:00:02.072134 taken by unCompressedRoutingTableReports\n",
      "loading fixed routes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:07:23 INFO: Time 0:00:01.253788 taken by LoadFixedRoutes\n",
      "Executing data specifications and loading data for system vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:07:30 INFO: Time 0:00:07.014927 taken by HostExecuteSystemDataSpecification\n",
      "Loading system executables onto the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:07:36 INFO: Time 0:00:05.950342 taken by LoadSystemExecutableImages\n",
      "Clearing tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Loading Tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:07:36 INFO: Time 0:00:00.185416 taken by TagsLoader\n",
      "Writing data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:07:39 INFO: Time 0:00:02.760205 taken by WriteMemoryIOData\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing data specifications and loading data for application vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:09:16 INFO: Time 0:01:37.482568 taken by HostExecuteApplicationDataSpecification\n",
      "Writing fixed route report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:09:17 INFO: Time 0:00:01.313935 taken by FixedRouteFromMachineReport\n",
      "Loading executables onto the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:09:22 INFO: Time 0:00:04.932555 taken by LoadApplicationExecutableImages\n",
      "Reading Routing Tables from Machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:09:55 INFO: Time 0:00:32.102671 taken by RoutingTableFromMachineReport\n",
      "Generating compressed router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:09:56 INFO: Time 0:00:01.973245 taken by compressedRoutingTableReports\n",
      "Generating comparison of router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:09:57 INFO: Time 0:00:00.260935 taken by comparisonOfRoutingTablesReport\n",
      "2020-07-19 19:09:57 INFO: Running for 1 steps for a total of 120000ms\n",
      "2020-07-19 19:09:57 INFO: Run 1 of 1\n",
      "Generating SDRAM usage report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:10:03 INFO: Time 0:00:06.485440 taken by SdramUsageReportPerChip\n",
      "Updating run time\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:10:07 INFO: Time 0:00:04.104492 taken by ChipRuntimeUpdater\n",
      "Getting provenance data from machine graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:10:13 INFO: Time 0:00:05.352813 taken by GraphProvenanceGatherer\n",
      "2020-07-19 19:10:13 INFO: Time 0:00:00.003329 taken by DatabaseInterface\n",
      "2020-07-19 19:10:13 INFO: ** Notifying external sources that the database is ready for reading **\n",
      "2020-07-19 19:10:13 INFO: Time 0:00:00.001874 taken by NotificationProtocol\n",
      "2020-07-19 19:10:13 INFO: *** Running simulation... *** \n",
      "Loading buffers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:10:13 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2020-07-19 19:10:13 INFO: ** Sending start / resume message to external sources to state the simulation has started or resumed. **\n",
      "2020-07-19 19:10:13 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2020-07-19 19:10:13 INFO: Application started; waiting 1200.1s for it to stop\n",
      "2020-07-19 19:30:13 INFO: ** Sending pause / stop message to external sources to state the simulation has been paused or stopped. **\n",
      "2020-07-19 19:30:13 INFO: Time 0:20:00.301308 taken by ApplicationRunner\n",
      "Extracting buffers from the last run\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:39:15 INFO: Time 0:09:02.466982 taken by BufferExtractor\n",
      "Getting provenance data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:39:18 INFO: Time 0:00:02.738553 taken by PlacementsProvenanceGatherer\n",
      "Getting Router Provenance\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:39:20 INFO: Time 0:00:02.155124 taken by RouterProvenanceGatherer\n",
      "Getting profile data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2020-07-19 19:39:23 INFO: Time 0:00:02.761922 taken by ProfileDataGatherer\n",
      "2020-07-19 19:39:48 INFO: Turning off machine\n",
      "2020-07-19 19:39:48 WARNING: The router on 16, 33 has default routed 96000 multicast packets, but the router table did not expect any default routed packets. This occurs where the router has no entry associated with the multi-cast key. Try investigating the keys allocated to the vertices and the router table entries for this chip.\n",
      "2020-07-19 19:39:48 WARNING: The extra monitor on 17, 33 has detected that 17 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely a overestimate.\n",
      "2020-07-19 19:39:48 WARNING: The router on 21, 20 has default routed 96000 multicast packets, but the router table did not expect any default routed packets. This occurs where the router has no entry associated with the multi-cast key. Try investigating the keys allocated to the vertices and the router table entries for this chip.\n",
      "2020-07-19 19:39:48 WARNING: The extra monitor on 21, 24 has detected that 7 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely a overestimate.\n",
      "2020-07-19 19:39:48 WARNING: The extra monitor on 34, 6 has detected that 15 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely a overestimate.\n",
      "2020-07-19 19:39:48 WARNING: The extra monitor on 34, 14 has detected that 14 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely a overestimate.\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2017-2019 The University of Manchester\n",
    "#\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "import math\n",
    "import os\n",
    "# from pacman.model.graphs.machine import MachineEdge\n",
    "\n",
    "import spinnaker_graph_front_end as front_end\n",
    "\n",
    "# 12000\n",
    "runtime = 120000\n",
    "time_step = 10000\n",
    "MAX_X_SIZE_OF_FABRIC = 128\n",
    "MAX_Y_SIZE_OF_FABRIC = 128\n",
    "n_chips = (MAX_X_SIZE_OF_FABRIC * MAX_Y_SIZE_OF_FABRIC) // 10\n",
    "\n",
    "ex = [0, 1, 0, -1, 0, 1, -1, -1, 1]\n",
    "ey = [0, 0, 1, 0, -1, 1, 1, -1, -1]\n",
    "\n",
    "\n",
    "\n",
    "def initVelocity(x_pos, y_pos):\n",
    "    \"\"\"\n",
    "    Init the velocity u, v = (u_x, u_y)\n",
    "  \n",
    "    ydim = xdim = N = 128\n",
    "    K = 30 / N\n",
    "    delta = 0.05\n",
    "  \n",
    "    u = tanh( K (y - 0.25 * ydim) ) for y <= 0.5 * ydim \n",
    "    u = U_0 tanh( K (0.75 * ydim - y) ) for y >  0.5 * ydim\n",
    "    v = delta sin( 2pi *x / xdim )\n",
    "    \"\"\"\n",
    "    U_0 = 0.01\n",
    "    K = 30.0\n",
    "    delta = 0.05\n",
    "    x_temp = 1.0 * (x_pos) / MAX_X_SIZE_OF_FABRIC\n",
    "    y_temp = 1.0 * (y_pos) / MAX_Y_SIZE_OF_FABRIC\n",
    "    if y_temp <= 0.5:\n",
    "        u_x = U_0 * math.tanh(K * (y_temp - 0.25))\n",
    "    else:\n",
    "        u_x = U_0 * math.tanh(K * (0.75 - y_temp))\n",
    "    u_y = U_0 * delta * math.sin(2 * math.pi * (x_temp + 0.25))\n",
    "    return u_x, u_y\n",
    "\n",
    "\n",
    "# set up the front end and ask for the detected machines dimensions\n",
    "front_end.setup(\n",
    "    n_chips_required=n_chips, model_binary_folder=os.path.dirname(os.path.abspath(\"__file__\")), machine_time_step=time_step,time_scale_factor=10)\n",
    "\n",
    "# figure out if machine can handle simulation\n",
    "cores = front_end.get_number_of_available_cores_on_machine()\n",
    "\n",
    "# chech if there is enough cores\n",
    "if cores <= (MAX_X_SIZE_OF_FABRIC * MAX_Y_SIZE_OF_FABRIC):\n",
    "    raise KeyError(\"Don't have enough cores to run simulation\")\n",
    "\n",
    "# contain the vertices for the connection aspect\n",
    "vertices = [\n",
    "    [None for _ in range(MAX_X_SIZE_OF_FABRIC)]\n",
    "    for _ in range(MAX_Y_SIZE_OF_FABRIC)]\n",
    "\n",
    "# build vertices\n",
    "for x in range(0, MAX_X_SIZE_OF_FABRIC):\n",
    "    for y in range(0, MAX_Y_SIZE_OF_FABRIC):\n",
    "        u_x, u_y = initVelocity(x, y)\n",
    "        vert = LatticeBasicCell(\n",
    "            \"cell{}\".format((x * MAX_X_SIZE_OF_FABRIC) + y),\n",
    "            x, y, u_x, u_y)\n",
    "        vertices[x][y] = vert\n",
    "        front_end.add_machine_vertex_instance(vert)\n",
    "\n",
    "# build edges\n",
    "for x in range(0, MAX_X_SIZE_OF_FABRIC):\n",
    "    for y in range(0, MAX_Y_SIZE_OF_FABRIC):\n",
    "        #   diraction = [\"me\", \"n\", \"w\", \"s\", \"e\", \"nw\", \"sw\", \"se\", \"ne\"]\n",
    "        positions = [\n",
    "            (x, (y + 1) % MAX_Y_SIZE_OF_FABRIC, \"E\"),\n",
    "            ((x + 1) % MAX_X_SIZE_OF_FABRIC,\n",
    "             (y + 1) % MAX_Y_SIZE_OF_FABRIC, \"SE\"),\n",
    "            ((x + 1) % MAX_X_SIZE_OF_FABRIC, y, \"S\"),\n",
    "            ((x + 1) % MAX_X_SIZE_OF_FABRIC,\n",
    "             (y - 1) % MAX_Y_SIZE_OF_FABRIC, \"SW\"),\n",
    "            (x, (y - 1) % MAX_Y_SIZE_OF_FABRIC, \"W\"),\n",
    "            ((x - 1) % MAX_X_SIZE_OF_FABRIC,\n",
    "             (y - 1) % MAX_Y_SIZE_OF_FABRIC, \"NW\"),\n",
    "            ((x - 1) % MAX_X_SIZE_OF_FABRIC, y, \"N\"),\n",
    "            ((x - 1) % MAX_X_SIZE_OF_FABRIC,\n",
    "             (y + 1) % MAX_Y_SIZE_OF_FABRIC, \"NE\")]\n",
    "\n",
    "         # build edges for each direction for this vertex\n",
    "        for (dest_x, dest_y, compass) in positions:\n",
    "            front_end.add_machine_edge_instance(LatticeEdge( vertices[x][y], vertices[dest_x][dest_y],compass, \"edge between {} and {}\".format(vertices[x][y], vertices[dest_x][dest_y])), LatticeBasicCell.PARTITION_ID)\n",
    "            vertices[x][y].set_direction_vertex(direction=compass, vertex=vertices[dest_x][dest_y])\n",
    "\n",
    "# run the simulation\n",
    "front_end.run(runtime)\n",
    "\n",
    "# get recorded data\n",
    "recorded_data = dict()\n",
    "\n",
    "# if not front_end.use_virtual_machine():\n",
    "buffer_manager = front_end.buffer_manager()\n",
    "\n",
    "# get the data per vertex\n",
    "for x in range(0, MAX_X_SIZE_OF_FABRIC):\n",
    "    for y in range(0, MAX_Y_SIZE_OF_FABRIC):\n",
    "        recorded_data[x, y] = vertices[x][y].get_data(\n",
    "            front_end.buffer_manager(),\n",
    "            front_end.placements().get_placement_of_vertex(\n",
    "                vertices[x][y]))\n",
    "\n",
    "# clear the machine\n",
    "front_end.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recorded_data[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualise it in text form (bad but no vis this time)\n",
    "u_x_output = collections.defaultdict(dict)\n",
    "u_y_output = collections.defaultdict(dict)\n",
    "for i in range(0, MAX_X_SIZE_OF_FABRIC):\n",
    "    for j in range(0, MAX_Y_SIZE_OF_FABRIC):\n",
    "        u_x_output[i][j] = recorded_data[i, j][23998]\n",
    "        u_y_output[i][j] = recorded_data[i, j][23999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate the voriticity\n",
    "voriticity = collections.defaultdict(dict)\n",
    "\n",
    "for i in range(0, MAX_X_SIZE_OF_FABRIC):\n",
    "    for j in range(0, MAX_Y_SIZE_OF_FABRIC): \n",
    "        voriticity[i][j] = 0.5 * (u_y_output[(i + 1) % MAX_X_SIZE_OF_FABRIC][j] - u_y_output[(i - 1)%MAX_X_SIZE_OF_FABRIC][j]) + 0.5 * (u_x_output[i][(j + 1)%MAX_Y_SIZE_OF_FABRIC] - u_x_output[i][(j - 1) % MAX_Y_SIZE_OF_FABRIC])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d59d295a36a4c93a09ec003603de6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spinnaker/sPyNNaker/lib/python3.6/site-packages/ipykernel_launcher.py:10: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/spinnaker/sPyNNaker/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: linewidths is ignored by contourf\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Visulize the voriticity with contour\n",
    "data = pd.DataFrame.from_dict(voriticity).T\n",
    "X = np.linspace(0,127,128)\n",
    "Y = np.linspace(0,127,128)\n",
    "def f(X,Y):\n",
    "    return (data.iloc[X,Y])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title('128 * 128 contour of Vorticity')\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.contour(X, Y, f(X,Y),127, colors='k', linewidths=(0.7,))\n",
    "plt.contourf(X, Y, f(X,Y),127, alpha=0.25, colors='black', linewidths=0.7)\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.to_csv(r'Vorticity_128*128.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sPyNNaker",
   "language": "python",
   "name": "spynnaker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
